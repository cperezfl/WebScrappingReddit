{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mkfvsOf7fDZI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Taller 1 Visualización de Datos\n",
        "\n",
        "**Integrante:** Christian Pérez Flores\n",
        "\n",
        "**Profesora:** Ana Moya Beltrán\n",
        "\n",
        "**Ayudante:** Diego Santibáñez\n"
      ],
      "metadata": {
        "id": "6iOZS0aO7Kbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bibliotecas y conexión a API de Reddit"
      ],
      "metadata": {
        "id": "4kWLz_lSe3dh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar se instalan e importan las bibliotecas necesarias, utilizando PRAW para conectarnos a la API de Reddit gracias a las credenciales obtenidas a través de [Reddit Apps](https://www.reddit.com/prefs/apps/)"
      ],
      "metadata": {
        "id": "HlK0DcY22Wtu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmJsn5QQEcko",
        "outputId": "eef7b72e-ceee-4fcb-c00c-bdd4926cf940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: duckdb in /usr/local/lib/python3.11/dist-packages (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install duckdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv-eQ09PEe9M",
        "outputId": "38a14e12-f01b-4706-c8c3-d99c4555852a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.11/dist-packages (7.8.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import praw\n",
        "import datetime"
      ],
      "metadata": {
        "id": "xfwQxzSXEwVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit = praw.Reddit(\n",
        "     client_id=\"M04shejV766NFiwJlZ-QIQ\",\n",
        "     client_secret=\"THwpb6fViqOf9biT1VoQo3vSNtNDkg\",\n",
        "     user_agent=\"Fun_School8641\",\n",
        "     check_for_async=False\n",
        ")"
      ],
      "metadata": {
        "id": "LgSKpuoTE28X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracción de datos"
      ],
      "metadata": {
        "id": "mkfvsOf7fDZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se eligen las comunidades a explorar y se organiza la estructura que recibirá la información extraida, en este caso se optó por transformar los datos desde dos dataframes distintos (posts y comentarios) a dos archivos CSV distintos, cada uno con sus nombres respectivos para no generar confusiones en trabajos futuros.\n"
      ],
      "metadata": {
        "id": "K5Vl6jdk2abX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elección de comunidades"
      ],
      "metadata": {
        "id": "j3oq_i3P1RUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las comunidades elegidas buscan tener enfoques distintos, que permitan generar análisis y gráficos variados y diferenciados entre sí, se eligieron tres subreddits con comportamientos y características distintas."
      ],
      "metadata": {
        "id": "pyb8U_cU2gEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   **SplatoonMeta:** Comunidad de discusión para el videojuego Splatoon, en ella se habla sobre estrategias e información referida al mismo en un contexto de competitividad. Se eligió esta comunidad debido a la variedad de elementos relacionadas al videojuego que se mencionan (nombres de distintas armas, roles de miembros de un equipo, nombres de estrategias y composiciones de equipo, distintos torneos, entre otros), lo que podría permitir generar gráficos variados, además de su comportamiento enfocado en la colaboración estratégica, el análisis técnico y el intercambio de información de alto nivel, lo que responde a su naturaleza competitiva y orientada a los e-sports, los miembros de esta comunidad no participan solo como jugadores casuales, sino como analistas, estrategas y competidores activos."
      ],
      "metadata": {
        "id": "1depAD7o2KPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SplatoonMeta = \"SplatoonMeta\""
      ],
      "metadata": {
        "id": "xMenhvERZuBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.   **LearnPython**: Comunidad dedicada al aprendizaje del lenguaje de programación Python, orientada principalmente a principiantes. En ella se comparten dudas, recursos, ejemplos de código y consejos prácticos. Se eligió esta comunidad debido a la variedad de temas relacionados al proceso de aprendizaje que se mencionan, coo errores comunes, recomendaciones de cursos, preguntas frecuentes o aplicaciones básicas. Además, presenta un comportamiento centrado en la colaboración, la resolución colectiva de problemas y el apoyo entre aprendices, lo que responde a su naturaleza formativa y accesible."
      ],
      "metadata": {
        "id": "7vNo0Bxa1ly_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LearnPython = \"learnpython\""
      ],
      "metadata": {
        "id": "1ORWzEY61uhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.   **AskBaking**: Comunidad enfocada a resolver dudas y compartir consejos sobre repostería, donde los miembros buscan mejorar sus técnicas, experimentar con nuevas recetas o solucionar problemas comunes al hornear. Se eligió esta comunidad debido a la variedad de interacciones que se dan, como preguntas específicas sobre ingredientes, técnicas de decoración, consejos prácticos y recomendaciones de productos, lo que podría permitir generar análisis sobre las tendencias de preguntas más frecuentes y los temas más discutidos. Además, el comportamiento de la comunidad se centra más en el intercambio informal de experiencias y el apoyo mutuo, con un ambiente más relajado y colaborativo orientado al disfrute personal y el aprendizaje a través de la experimentación."
      ],
      "metadata": {
        "id": "EbQ9uANY1q-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AskBaking = \"askbaking\""
      ],
      "metadata": {
        "id": "2UAdMf4X11Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estructuración y extracción de resultados"
      ],
      "metadata": {
        "id": "wy00kQqK19dX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar se visualizó información básica y pública de las comunidades elegidas, principalmente para verificar que existiera una cantidad adecueda de suscriptores y una fecha de creación razonable, para así asegurar tener una cantidad de publicaciones y comentarios necesaria (al menos 100 publicaciones con al menos 10 comentarios cada una)."
      ],
      "metadata": {
        "id": "oB9EnnZi2PR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def info_subreddit(subreddit):\n",
        "  print(f\"Nombre completo: r/{subreddit.display_name}\")\n",
        "  print(f\"Titulo: {subreddit.title}\")\n",
        "  print(f\"Descripción: {subreddit.public_description}\")\n",
        "  print(f\"Suscriptores: {subreddit.subscribers}\")\n",
        "  print(f\"Usuarios activos: {subreddit.accounts_active}\")\n",
        "  print(f\"Fecha de creación: {datetime.datetime.fromtimestamp(subreddit.created_utc).strftime('%Y-%m-%d %H:%M:%S')}\")"
      ],
      "metadata": {
        "id": "vCzTIschH9fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info_subreddit(reddit.subreddit(SplatoonMeta))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJeN-cOXJ4jI",
        "outputId": "0cc31615-00e5-43e2-8af2-0a3e52b0fdba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre completo: r/SplatoonMeta\n",
            "Titulo: Competitive Splatoon Discussion\n",
            "Descripción: This sub is for discussion of Splatoon as a competitive game, including its metagame, strategies, and esports-related information. Feel free to ask for help and advice for improving your skills.  Please use /r/Splatoon or /r/Splatoon_3 for general Splatoon posts.\n",
            "Suscriptores: 9776\n",
            "Usuarios activos: 5\n",
            "Fecha de creación: 2015-05-29 09:00:10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info_subreddit(reddit.subreddit(LearnPython))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDS4bk9y6Ue3",
        "outputId": "399f0642-2838-4fff-9f45-5b4191fe74c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre completo: r/learnpython\n",
            "Titulo: Python Education\n",
            "Descripción: Subreddit for posting questions and asking for general advice about all topics related to learning python.\n",
            "Suscriptores: 918644\n",
            "Usuarios activos: 127\n",
            "Fecha de creación: 2009-10-02 15:59:41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info_subreddit(reddit.subreddit(AskBaking))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGgLp8Je6WW3",
        "outputId": "7ab20136-6a85-435a-b70a-ebb3671d1dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre completo: r/askbaking\n",
            "Titulo: Ask Baking\n",
            "Descripción: Welcome to /r/AskBaking! This subreddit is devoted to the discussion of questions related to baking, the process, and requests for help on your results!\n",
            "\n",
            "Please read the rules; posts will be deleted if they do not follow our rules.\n",
            "Suscriptores: 289602\n",
            "Usuarios activos: 35\n",
            "Fecha de creación: 2016-06-16 19:01:43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se definió una función que permitiera organizar los datos obtenidos tras la extracción con Web Scrapping.\n",
        "\n",
        "Para las publicaciones a extraer, se guardan:\n",
        "- ID del post  \n",
        "- Título  \n",
        "- Fecha de creación  (con formato año-mes-día y hora-minuto-segundo)\n",
        "- Autor (en caso de que el autor ya no exista, se le nombra como \"ELIMINADO\")\n",
        "- URL  \n",
        "- Número de comentarios  \n",
        "- Texto del post\n",
        "- Tiene texto (para determinar si la publicación tiene o no texto)\n",
        "- Puntaje\n",
        "\n",
        "Mientras que para los comentarios de las publicaciones extraidas, se guardan:\n",
        "- ID del post\n",
        "- ID del comentario  \n",
        "- Autor  \n",
        "- Texto\n",
        "- Fecha\n"
      ],
      "metadata": {
        "id": "JisZlDSq7O8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extraccion_info_post(post):\n",
        "  fecha = datetime.datetime.fromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n",
        "  autor = str(post.author) if post.author else \"ELIMINADO\"\n",
        "  tiene_texto = \"Sí\" if post.selftext else \"No\"\n",
        "\n",
        "  datos['id_post'].append(post.id)\n",
        "  datos['titulo_post'].append(post.title)\n",
        "  datos['fecha_post'].append(fecha)\n",
        "  datos['autor_post'].append(autor)\n",
        "  datos['URL'].append(post.url)\n",
        "  datos['numero_comentarios'].append(post.num_comments)\n",
        "  datos['texto_post'].append(post.selftext)\n",
        "  datos['tiene_texto'].append(tiene_texto)\n",
        "  datos['score'].append(post.score)\n",
        "\n",
        "  post.comments.replace_more(limit=0) #Evita cargar \"load more comments\"\n",
        "  for comment in post.comments[:10]:\n",
        "    if not comment.stickied:\n",
        "      comentarios['id_post'].append(post.id)\n",
        "      comentarios['id_comentario'].append(comment.id)\n",
        "      comentarios['autor_comentario'].append(str(comment.author) if comment.author else \"ELIMINADO\")\n",
        "      comentarios['texto_comentario'].append(comment.body)\n",
        "      comentarios['fecha_comentario'].append(datetime.datetime.fromtimestamp(comment.created_utc).strftime('%Y-%m-%d %H:%M:%S'))"
      ],
      "metadata": {
        "id": "nN8UNmdmNPAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la extracción de las publicaciones se crea la estructura necesaria para almacenar los datos requeridos según lo explicado con anterioridad. En este caso se limitó el máximo número de publicaciones a 150 por comodidad pero podría aumentarse en un futuro de ser necesario, se consideran publicaciones válidas a aquellas con un mínimo de 10 comentarios cada una.\n",
        "\n",
        "Una vez que los datos son extraídos se separan en dos dataframes distintos (posts y comentarios), los que posteriormente se transforman en un archivo CSV para trabajos futuros."
      ],
      "metadata": {
        "id": "N7d6-teV8RVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extraer_posts_validos(sub, max_posts=150, min_comentarios=10):\n",
        "    global datos, comentarios  # <-- Permite que la estructura a crear sea global y se pueda usar en las distintas funciones.\n",
        "\n",
        "    # Creación y reinicio de la estructura para empezar \"limpio\" luego de la primera extraacción,\n",
        "    # de otro modo las siguientes almacenarían los resultados de las comunidades anteriores.\n",
        "\n",
        "    datos = {\n",
        "        'id_post': [],\n",
        "        'titulo_post': [],\n",
        "        'fecha_post': [],\n",
        "        'autor_post': [],\n",
        "        'URL': [],\n",
        "        'numero_comentarios': [],\n",
        "        'texto_post': [],\n",
        "        'tiene_texto': [],\n",
        "        'score': []\n",
        "    }\n",
        "\n",
        "    comentarios = {\n",
        "        'id_post': [],\n",
        "        'id_comentario': [],\n",
        "        'autor_comentario': [],\n",
        "        'texto_comentario': [],\n",
        "        'fecha_comentario': []\n",
        "    }\n",
        "\n",
        "    posts_almacenados = set()\n",
        "    contador_validos = 0 #Permitirá verificar que exista la cantidad necesaria de publicaciones\n",
        "\n",
        "    for submission in sub.top(limit=None, time_filter='all'):\n",
        "        if submission.id in posts_almacenados: #Evita que hayan publicaciones duplicadas\n",
        "            continue\n",
        "        if submission.num_comments < min_comentarios: #Se salta las publicaciones con menos de 10 comentarios\n",
        "            continue\n",
        "\n",
        "        extraccion_info_post(submission)\n",
        "        posts_almacenados.add(submission.id)\n",
        "        contador_validos += 1\n",
        "\n",
        "        if contador_validos >= max_posts and contador_validos >= 100:\n",
        "            break  # Salimos del for aquí, y el guardado se hace después\n",
        "\n",
        "    if contador_validos >= 100: #Se asegura que haya al menos la cantidad requerida de publicaciones antes de guardar en los respectivos dataframes\n",
        "        df_posts = pd.DataFrame(datos)\n",
        "        df_comentarios = pd.DataFrame(comentarios)\n",
        "        nombre_sub = sub.display_name.lower()\n",
        "        df_posts.to_csv(f'posts_{nombre_sub}.csv', index=False, encoding='utf-8-sig') #Se genera el CSV para almacenar publicaciones\n",
        "        df_comentarios.to_csv(f'comentarios_{nombre_sub}.csv', index=False, encoding='utf-8-sig') #Se genera el CSV para almacenar comentarios\n",
        "        print(f\"Número de posts válidos almacenados: {contador_validos}\")\n",
        "    else: #En caso de no haberse guardado 100 posts como mínimo, entonces se manda un mensaje en pantalla\n",
        "        print(f\"Número de posts válidos almacenados: {contador_validos}, no se ha generado ningún archivo CSV\")"
      ],
      "metadata": {
        "id": "5_U6JMkXd0kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se llaman a las funciones creadas para la extracción de los resultados, pasándole el nombre de las comunidades previamente elegidas, lo que generará los CSV respectivos."
      ],
      "metadata": {
        "id": "NaTyXbrACfLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub = reddit.subreddit(SplatoonMeta)\n",
        "extraer_posts_validos(sub)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF90hHorskb8",
        "outputId": "1d94b447-eecd-4c11-980b-8cf95d555dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de posts válidos almacenados: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub = reddit.subreddit(LearnPython)\n",
        "extraer_posts_validos(sub)"
      ],
      "metadata": {
        "id": "8ugKBcub0oND",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef6bc26-0ce5-459b-be6a-df299bfb5839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de posts válidos almacenados: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub = reddit.subreddit(AskBaking)\n",
        "extraer_posts_validos(sub)"
      ],
      "metadata": {
        "id": "Z47wwfNF0p_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b90276f-145c-4ca8-901d-1657c20a2fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de posts válidos almacenados: 150\n"
          ]
        }
      ]
    }
  ]
}